{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "853a9a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('MNIST.csv')\n",
    "data = np.array(data)\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f95c18dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = data.shape\n",
    "\n",
    "data_test = data[0:1000].T\n",
    "Y_test = data_test[0]\n",
    "X_test = data_test[1:n]\n",
    "X_test = X_test / 255\n",
    "\n",
    "data_train = data[1000:m].T\n",
    "Y_train = data_train[0]\n",
    "X_train = data_train[1:n]\n",
    "X_train = X_train / 255\n",
    "\n",
    "_, m_train = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "025dbe58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(785, 41000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9031288",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network:\n",
    "    def __init__(self, input_size, hidden_1_size, hidden_2_size, output_size, learning_rate, data_num, bias = 1):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_1_size = hidden_1_size\n",
    "        self.hidden_2_size = hidden_2_size\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.m = data_num\n",
    "\n",
    "        # self.W1 = np.random.rand(hidden_1_size, input_size) - 0.5\n",
    "        # self.b1 = np.random.rand(hidden_1_size, bias) - 0.5\n",
    "\n",
    "        # self.W2 = np.random.rand(hidden_2_size, hidden_1_size) - 0.5\n",
    "        # self.b2 = np.random.rand(hidden_2_size, bias) - 0.5\n",
    "\n",
    "        # self.W3 = np.random.rand(output_size, hidden_2_size) - 0.5\n",
    "        # self.b3 = np.random.rand(output_size, bias) - 0.5\n",
    "\n",
    "        # Xavier initialization for weights\n",
    "        self.W1 = np.random.randn(hidden_1_size, input_size) * np.sqrt(1.0 / input_size)\n",
    "        self.b1 = np.zeros((hidden_1_size, bias))\n",
    "\n",
    "        self.W2 = np.random.randn(hidden_2_size, hidden_1_size) * np.sqrt(1.0 / hidden_1_size)\n",
    "        self.b2 = np.zeros((hidden_2_size, bias))\n",
    "\n",
    "        self.W3 = np.random.randn(output_size, hidden_2_size) * np.sqrt(1.0 / hidden_2_size)\n",
    "        self.b3 = np.zeros((output_size, bias))\n",
    "\n",
    "    def set_learning_rate(self, new_LR):\n",
    "        self.learning_rate = new_LR\n",
    "\n",
    "    def forward_prop(self, X):\n",
    "        self.Z1 = self.W1.dot(X) + self.b1\n",
    "        self.A1 = ReLU(self.Z1)\n",
    "\n",
    "        self.Z2 = self.W2.dot(self.A1) + self.b2\n",
    "        self.A2 = ReLU(self.Z2)\n",
    "\n",
    "        self.Z3 = self.W3.dot(self.A2) + self.b3\n",
    "        self.A3 = softmax(self.Z3)\n",
    "\n",
    "        return self.A3, self.Z3\n",
    "\n",
    "    def backward_prop(self, X, y):\n",
    "        one_hot_Y = one_hot(y)\n",
    "\n",
    "        self.dZ3 = self.A3 - one_hot_Y\n",
    "        self.dW3 = 1 / self.m * self.dZ3.dot(self.A2.T)\n",
    "        self.db3 = 1 / self.m * np.sum(self.dZ3, axis = 1, keepdims = True)\n",
    "\n",
    "        self.dZ2 = self.W3.T.dot(self.dZ3) * ReLU_prime(self.Z2)\n",
    "        self.dW2 = 1 / self.m * self.dZ2.dot(self.A1.T)\n",
    "        self.db2 = 1 / self.m * np.sum(self.dZ2, axis = 1, keepdims = True)\n",
    "\n",
    "        self.dZ1 = self.W2.T.dot(self.dZ2) * ReLU_prime(self.Z1)\n",
    "        self.dW1 = 1 / self.m * self.dZ1.dot(X.T)\n",
    "        self.db1 = 1 / self.m * np.sum(self.dZ1, axis = 1, keepdims = True)\n",
    "\n",
    "        #return dW1, db1, dW2, db2, dW3, db3\n",
    "\n",
    "    def gradient_descent(self):\n",
    "        self.W1 = self.W1 - self.dW1 * self.learning_rate\n",
    "        self.b1 = self.b1 - self.db1 * self.learning_rate\n",
    "\n",
    "        self.W2 = self.W2 - self.dW2 * self.learning_rate\n",
    "        self.b2 = self.b2 - self.db2 * self.learning_rate\n",
    "\n",
    "        self.W3 = self.W3 - self.dW3 * self.learning_rate\n",
    "        self.b3 = self.b3 - self.db3 * self.learning_rate\n",
    "\n",
    "\n",
    "    def train_epochs(self, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            self.forward_prop(X_train)\n",
    "            self.backward_prop(X_train, Y_train)\n",
    "            self.gradient_descent()\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                predictions = np.argmax(self.A3, 0)\n",
    "                print(\"Epoch\", epoch, \":\", round((np.sum(predictions == Y_train) / Y_train.size) * 100, 2), \"%\")\n",
    "        print(\"Training complete\")\n",
    "\n",
    "# def get_predictions(A3):\n",
    "#     return np.argmax(A3, 0)\n",
    "\n",
    "# def get_accuracy(predictions, Y):\n",
    "#     return round((np.sum(predictions == Y) / Y.size) * 100, 2)\n",
    "        \n",
    "\n",
    "class PReLU:\n",
    "    def __init__(self, alpha_init = 0.01):\n",
    "        self.alpha = alpha_init\n",
    "\n",
    "    def forward(self, Z):\n",
    "        return np.maximum(self.alpha * Z, Z)\n",
    "\n",
    "    def prime(self, Z):\n",
    "        return np.where(Z > 0, 1, self.alpha)\n",
    "\n",
    "def update_alpha(alpha, dZ):\n",
    "    learning_rate = 0.01\n",
    "    alpha -= learning_rate * np.mean(np.where(dZ < 0, dZ * alpha, 0))\n",
    "    return alpha\n",
    "\n",
    "\n",
    "def ReLU(Z):\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "def ReLU_prime(Z):\n",
    "    return Z > 0\n",
    "\n",
    "\n",
    "\n",
    "def sigmoid(Z):\n",
    "    A = 1 / (1 + np.exp(np.clip(-Z, -4, 4)))\n",
    "    return A\n",
    "\n",
    "def sigmoid_prime(Z):\n",
    "    A = (sigmoid(Z) * (1 - sigmoid(Z)))\n",
    "    return A\n",
    "\n",
    "\n",
    "\n",
    "def softmax(Z):\n",
    "    A = np.exp(Z) / sum(np.exp(Z))\n",
    "    return A\n",
    "\n",
    "\n",
    "\n",
    "def one_hot(Y):\n",
    "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "    one_hot_Y = one_hot_Y.T\n",
    "    return one_hot_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b208f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : 9.77 %\n",
      "epoch 10 : 30.01 %\n",
      "epoch 20 : 41.84 %\n",
      "epoch 30 : 52.21 %\n",
      "epoch 40 : 61.09 %\n",
      "epoch 50 : 66.73 %\n",
      "epoch 60 : 71.89 %\n",
      "epoch 70 : 76.38 %\n",
      "epoch 80 : 79.22 %\n",
      "epoch 90 : 80.8 %\n",
      "epoch 100 : 82.09 %\n",
      "epoch 110 : 82.96 %\n",
      "epoch 120 : 83.71 %\n",
      "epoch 130 : 84.38 %\n",
      "epoch 140 : 85.0 %\n",
      "epoch 150 : 85.49 %\n",
      "epoch 160 : 85.95 %\n",
      "epoch 170 : 86.34 %\n",
      "epoch 180 : 86.74 %\n",
      "epoch 190 : 87.11 %\n",
      "epoch 200 : 87.38 %\n",
      "epoch 210 : 87.63 %\n",
      "epoch 220 : 87.83 %\n",
      "epoch 230 : 88.06 %\n",
      "epoch 240 : 88.27 %\n",
      "epoch 250 : 88.5 %\n",
      "epoch 260 : 88.66 %\n",
      "epoch 270 : 88.82 %\n",
      "epoch 280 : 88.97 %\n",
      "epoch 290 : 89.15 %\n",
      "epoch 300 : 89.25 %\n",
      "epoch 310 : 89.38 %\n",
      "epoch 320 : 89.47 %\n",
      "epoch 330 : 89.57 %\n",
      "epoch 340 : 89.66 %\n",
      "epoch 350 : 89.78 %\n",
      "epoch 360 : 89.85 %\n",
      "epoch 370 : 89.93 %\n",
      "epoch 380 : 90.02 %\n",
      "epoch 390 : 90.09 %\n",
      "epoch 400 : 90.18 %\n",
      "epoch 410 : 90.23 %\n",
      "epoch 420 : 90.31 %\n",
      "epoch 430 : 90.42 %\n",
      "epoch 440 : 90.55 %\n",
      "epoch 450 : 90.61 %\n",
      "epoch 460 : 90.7 %\n",
      "epoch 470 : 90.76 %\n",
      "epoch 480 : 90.82 %\n",
      "epoch 490 : 90.9 %\n",
      "epoch 500 : 90.95 %\n",
      "epoch 510 : 91.01 %\n",
      "epoch 520 : 91.08 %\n",
      "epoch 530 : 91.15 %\n",
      "epoch 540 : 91.22 %\n",
      "epoch 550 : 91.28 %\n",
      "epoch 560 : 91.31 %\n",
      "epoch 570 : 91.37 %\n",
      "epoch 580 : 91.42 %\n",
      "epoch 590 : 91.49 %\n",
      "epoch 600 : 91.53 %\n",
      "epoch 610 : 91.6 %\n",
      "epoch 620 : 91.66 %\n",
      "epoch 630 : 91.71 %\n",
      "epoch 640 : 91.79 %\n",
      "epoch 650 : 91.84 %\n",
      "epoch 660 : 91.88 %\n",
      "epoch 670 : 91.93 %\n",
      "epoch 680 : 91.99 %\n",
      "epoch 690 : 92.02 %\n",
      "epoch 700 : 92.06 %\n",
      "epoch 710 : 92.11 %\n",
      "epoch 720 : 92.15 %\n",
      "epoch 730 : 92.21 %\n",
      "epoch 740 : 92.26 %\n",
      "epoch 750 : 92.31 %\n",
      "epoch 760 : 92.34 %\n",
      "epoch 770 : 92.4 %\n",
      "epoch 780 : 92.44 %\n",
      "epoch 790 : 92.48 %\n",
      "epoch 800 : 92.52 %\n",
      "epoch 810 : 92.56 %\n",
      "epoch 820 : 92.59 %\n",
      "epoch 830 : 92.64 %\n",
      "epoch 840 : 92.68 %\n",
      "epoch 850 : 92.71 %\n",
      "epoch 860 : 92.75 %\n",
      "epoch 870 : 92.77 %\n",
      "epoch 880 : 92.79 %\n",
      "epoch 890 : 92.81 %\n",
      "epoch 900 : 92.86 %\n",
      "epoch 910 : 92.89 %\n",
      "epoch 920 : 92.91 %\n",
      "epoch 930 : 92.94 %\n",
      "epoch 940 : 92.98 %\n",
      "epoch 950 : 93.01 %\n",
      "epoch 960 : 93.04 %\n",
      "epoch 970 : 93.07 %\n",
      "epoch 980 : 93.09 %\n",
      "epoch 990 : 93.11 %\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "nn = Neural_Network(784, 64, 32, 10, 0.05, 41000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3950c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : 95.17 %\n",
      "epoch 10 : 95.17 %\n",
      "epoch 20 : 95.17 %\n",
      "epoch 30 : 95.17 %\n",
      "epoch 40 : 95.17 %\n",
      "epoch 50 : 95.18 %\n",
      "epoch 60 : 95.17 %\n",
      "epoch 70 : 95.19 %\n",
      "epoch 80 : 95.19 %\n",
      "epoch 90 : 95.19 %\n",
      "epoch 100 : 95.19 %\n",
      "epoch 110 : 95.2 %\n",
      "epoch 120 : 95.21 %\n",
      "epoch 130 : 95.21 %\n",
      "epoch 140 : 95.21 %\n",
      "epoch 150 : 95.21 %\n",
      "epoch 160 : 95.21 %\n",
      "epoch 170 : 95.21 %\n",
      "epoch 180 : 95.21 %\n",
      "epoch 190 : 95.22 %\n",
      "epoch 200 : 95.22 %\n",
      "epoch 210 : 95.23 %\n",
      "epoch 220 : 95.24 %\n",
      "epoch 230 : 95.24 %\n",
      "epoch 240 : 95.25 %\n",
      "epoch 250 : 95.25 %\n",
      "epoch 260 : 95.26 %\n",
      "epoch 270 : 95.26 %\n",
      "epoch 280 : 95.26 %\n",
      "epoch 290 : 95.26 %\n",
      "epoch 300 : 95.26 %\n",
      "epoch 310 : 95.27 %\n",
      "epoch 320 : 95.27 %\n",
      "epoch 330 : 95.27 %\n",
      "epoch 340 : 95.27 %\n",
      "epoch 350 : 95.28 %\n",
      "epoch 360 : 95.28 %\n",
      "epoch 370 : 95.28 %\n",
      "epoch 380 : 95.28 %\n",
      "epoch 390 : 95.28 %\n",
      "epoch 400 : 95.28 %\n",
      "epoch 410 : 95.29 %\n",
      "epoch 420 : 95.3 %\n",
      "epoch 430 : 95.3 %\n",
      "epoch 440 : 95.3 %\n",
      "epoch 450 : 95.3 %\n",
      "epoch 460 : 95.31 %\n",
      "epoch 470 : 95.31 %\n",
      "epoch 480 : 95.31 %\n",
      "epoch 490 : 95.32 %\n",
      "epoch 500 : 95.32 %\n",
      "epoch 510 : 95.33 %\n",
      "epoch 520 : 95.33 %\n",
      "epoch 530 : 95.33 %\n",
      "epoch 540 : 95.34 %\n",
      "epoch 550 : 95.34 %\n",
      "epoch 560 : 95.33 %\n",
      "epoch 570 : 95.34 %\n",
      "epoch 580 : 95.34 %\n",
      "epoch 590 : 95.34 %\n",
      "epoch 600 : 95.34 %\n",
      "epoch 610 : 95.35 %\n",
      "epoch 620 : 95.36 %\n",
      "epoch 630 : 95.36 %\n",
      "epoch 640 : 95.36 %\n",
      "epoch 650 : 95.36 %\n",
      "epoch 660 : 95.37 %\n",
      "epoch 670 : 95.38 %\n",
      "epoch 680 : 95.38 %\n",
      "epoch 690 : 95.38 %\n",
      "epoch 700 : 95.39 %\n",
      "epoch 710 : 95.39 %\n",
      "epoch 720 : 95.39 %\n",
      "epoch 730 : 95.4 %\n",
      "epoch 740 : 95.4 %\n",
      "epoch 750 : 95.4 %\n",
      "epoch 760 : 95.4 %\n",
      "epoch 770 : 95.4 %\n",
      "epoch 780 : 95.4 %\n",
      "epoch 790 : 95.4 %\n",
      "epoch 800 : 95.41 %\n",
      "epoch 810 : 95.41 %\n",
      "epoch 820 : 95.41 %\n",
      "epoch 830 : 95.41 %\n",
      "epoch 840 : 95.41 %\n",
      "epoch 850 : 95.41 %\n",
      "epoch 860 : 95.41 %\n",
      "epoch 870 : 95.42 %\n",
      "epoch 880 : 95.42 %\n",
      "epoch 890 : 95.42 %\n",
      "epoch 900 : 95.42 %\n",
      "epoch 910 : 95.43 %\n",
      "epoch 920 : 95.43 %\n",
      "epoch 930 : 95.44 %\n",
      "epoch 940 : 95.44 %\n",
      "epoch 950 : 95.44 %\n",
      "epoch 960 : 95.44 %\n",
      "epoch 970 : 95.45 %\n",
      "epoch 980 : 95.45 %\n",
      "epoch 990 : 95.46 %\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "nn.set_learning_rate(0.01)\n",
    "nn.train_epochs(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0db93b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
