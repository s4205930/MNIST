{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "853a9a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('MNIST.csv')\n",
    "data = np.array(data)\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f95c18dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = data.shape\n",
    "\n",
    "data_test = data[0:1000].T\n",
    "Y_test = data_test[0]\n",
    "X_test = data_test[1:n]\n",
    "X_test = X_test / 255\n",
    "\n",
    "data_train = data[1000:m].T\n",
    "Y_train = data_train[0]\n",
    "X_train = data_train[1:n]\n",
    "X_train = X_train / 255\n",
    "\n",
    "_, m_train = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "025dbe58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(785, 41000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9031288",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PReLU:\n",
    "    def __init__(self, alpha_init = 0.01):\n",
    "        self.alpha = alpha_init\n",
    "\n",
    "    def forward(self, Z):\n",
    "        return np.maximum(self.alpha * Z, Z)\n",
    "\n",
    "    def prime(self, Z):\n",
    "        return np.where(Z > 0, 1, self.alpha)\n",
    "\n",
    "def update_alpha(alpha, dZ):\n",
    "    learning_rate = 0.01\n",
    "    alpha -= learning_rate * np.mean(np.where(dZ < 0, dZ * alpha, 0))\n",
    "    return alpha\n",
    "\n",
    "prelu_1 = PReLU()\n",
    "prelu_2 = PReLU()\n",
    "\n",
    "\n",
    "\n",
    "def ReLU(Z):\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "def ReLU_prime(Z):\n",
    "    return Z > 0\n",
    "\n",
    "\n",
    "\n",
    "def sigmoid(Z):\n",
    "    A = 1 / (1 + np.exp(np.clip(-Z, -4, 4)))\n",
    "    return A\n",
    "\n",
    "def sigmoid_prime(Z):\n",
    "    A = (sigmoid(Z) * (1 - sigmoid(Z)))\n",
    "    return A\n",
    "\n",
    "\n",
    "\n",
    "def softmax(Z):\n",
    "    A = np.exp(Z) / sum(np.exp(Z))\n",
    "    return A\n",
    "\n",
    "\n",
    "\n",
    "def one_hot(Y):\n",
    "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "    one_hot_Y = one_hot_Y.T\n",
    "    return one_hot_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "547c872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(input, hidden_1, hidden_2, output, bias = 1):\n",
    "    W1 = np.random.rand(hidden_1, input) - 0.5\n",
    "    b1 = np.random.rand(hidden_1, bias) - 0.5\n",
    "\n",
    "    W2 = np.random.rand(hidden_2, hidden_1) - 0.5\n",
    "    b2 = np.random.rand(hidden_2, bias) - 0.5\n",
    "\n",
    "    W3 = np.random.rand(output, hidden_2) - 0.5\n",
    "    b3 = np.random.rand(output, bias) - 0.5\n",
    "    return W1, b1, W2, b2, W3, b3\n",
    "\n",
    "def forward_prop(W1, b1, W2, b2, W3, b3, X):\n",
    "    Z1 = W1.dot(X) + b1\n",
    "    A1 = ReLU(Z1)\n",
    "\n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    A2 = ReLU(Z2)\n",
    "\n",
    "    Z3 = W3.dot(A2)\n",
    "    A3 = softmax(Z3)\n",
    "\n",
    "    return Z1, A1, Z2, A2, Z3, A3\n",
    "\n",
    "def backward_prop(Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, X, Y):\n",
    "    one_hot_Y = one_hot(Y)\n",
    "\n",
    "    dZ3 = A3 - one_hot_Y\n",
    "    dW3 = 1 / m * dZ3.dot(A2.T)\n",
    "    db3 = 1 / m * np.sum(dZ3, axis = 1, keepdims = True)\n",
    "\n",
    "    dZ2 = W3.T.dot(dZ3) * ReLU_prime(Z2)\n",
    "    dW2 = 1 / m * dZ2.dot(A1.T)\n",
    "    db2 = 1 / m * np.sum(dZ2, axis = 1, keepdims = True)\n",
    "\n",
    "    dZ1 = W2.T.dot(dZ2) * ReLU_prime(Z1)\n",
    "    dW1 = 1 / m * dZ1.dot(X.T)\n",
    "    db1 = 1 / m * np.sum(dZ1, axis = 1, keepdims = True)\n",
    "\n",
    "    # prelu_1.alpha = update_alpha(prelu_1.alpha, dZ1)\n",
    "    # prelu_2.alpha = update_alpha(prelu_2.alpha, dZ1)\n",
    "    \n",
    "    return dW1, db1, dW2, db2, dW3, db3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53cdad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training algs\n",
    "\n",
    "def gradient_descent(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3, alpha):\n",
    "    W1 = W1 - alpha * dW1\n",
    "    b1 = b1 - alpha * db1\n",
    "\n",
    "    W2 = W2 - alpha * dW2\n",
    "    b2 = b2 - alpha * db2\n",
    "\n",
    "    W3 = W3 - alpha * dW3\n",
    "    b3 = b3 - alpha * db3\n",
    "\n",
    "    return W1, b1, W2, b2, W3, b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cf0eb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(X, W1, b1, W2, b2, W3, b3):\n",
    "    _, _, _, _, Z3, A3 = forward_prop(W1, b1, W2, b2, W3, b3, X)\n",
    "    predictions = get_predictions(A3)\n",
    "    confidence = np.max(softmax(Z3), axis = 0)\n",
    "    return predictions, confidence\n",
    "\n",
    "def test_results(idx, W1, b1, W2, b2, W3, b3):\n",
    "    curr_img = X_train[:, idx, None]\n",
    "    prediction, confidence = make_predictions(X_train[:, idx, None], W1, b1, W2, b2, W3, b3)\n",
    "    label = Y_train[idx]\n",
    "\n",
    "    print('Prediction:', prediction)\n",
    "    print('actual:', label)\n",
    "    print('confidence:', confidence)\n",
    "\n",
    "    curr_img = curr_img.reshape((28, 28)) * 255\n",
    "    plt.gray()\n",
    "    plt.imshow(curr_img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "505b4103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(A3):\n",
    "    return np.argmax(A3, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    return round((np.sum(predictions == Y) / Y.size) * 100, 2)\n",
    "\n",
    "def train(X, Y, epochs, alpha):\n",
    "    W1, b1, W2, b2, W3, b3 = init_params(784, 64, 32, 10) #ONLY CHANGE HIDDEN LAYERS!!!!\n",
    "\n",
    "    for e in range(epochs):\n",
    "        Z1, A1, Z2, A2, Z3, A3 = forward_prop(W1, b1, W2, b2, W3, b3, X)\n",
    "        dW1, db1, dW2, db2, dW3, db3 = backward_prop(Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, X, Y)\n",
    "        W1, b1, W2, b2, W3, b3 = gradient_descent(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3, alpha)\n",
    "\n",
    "        if e % 50 == 0:\n",
    "            print(\"Epoch:\", e)\n",
    "            print(\"Accuracy:\", get_accuracy(get_predictions(A3), Y), \"%\")\n",
    "\n",
    "    print(\"Epoch:\", e)\n",
    "    print(\"Accuracy:\", get_accuracy(get_predictions(A3), Y), \"%\")\n",
    "\n",
    "    return W1, b1, W2, b2, W3, b3\n",
    "\n",
    "def continue_train(X, Y, epochs, alpha, W1, b1, W2, b2, W3, b3):\n",
    "\n",
    "    for e in range(epochs):\n",
    "        Z1, A1, Z2, A2, Z3, A3 = forward_prop(W1, b1, W2, b2, W3, b3, X)\n",
    "        dW1, db1, dW2, db2, dW3, db3 = backward_prop(Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, X, Y)\n",
    "        W1, b1, W2, b2, W3, b3 = gradient_descent(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3, alpha)\n",
    "\n",
    "        if e % 50 == 0:\n",
    "            print(\"Epoch:\", e)\n",
    "            print(\"Accuracy:\", get_accuracy(get_predictions(A3), Y), \"%\")\n",
    "\n",
    "    print(\"Epoch:\", e)\n",
    "    print(\"Accuracy:\", get_accuracy(get_predictions(A3), Y), \"%\")\n",
    "\n",
    "    return W1, b1, W2, b2, W3, b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a6735dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Accuracy: 6.67 %\n",
      "Epoch: 50\n",
      "Accuracy: 69.88 %\n",
      "Epoch: 100\n",
      "Accuracy: 78.39 %\n",
      "Epoch: 150\n",
      "Accuracy: 82.07 %\n",
      "Epoch: 200\n",
      "Accuracy: 84.41 %\n",
      "Epoch: 250\n",
      "Accuracy: 86.03 %\n",
      "Epoch: 300\n",
      "Accuracy: 87.19 %\n",
      "Epoch: 350\n",
      "Accuracy: 88.07 %\n",
      "Epoch: 400\n",
      "Accuracy: 88.71 %\n",
      "Epoch: 450\n",
      "Accuracy: 89.24 %\n",
      "Epoch: 500\n",
      "Accuracy: 89.78 %\n",
      "Epoch: 550\n",
      "Accuracy: 90.22 %\n",
      "Epoch: 600\n",
      "Accuracy: 90.57 %\n",
      "Epoch: 650\n",
      "Accuracy: 90.89 %\n",
      "Epoch: 700\n",
      "Accuracy: 91.15 %\n",
      "Epoch: 750\n",
      "Accuracy: 91.41 %\n",
      "Epoch: 800\n",
      "Accuracy: 91.66 %\n",
      "Epoch: 850\n",
      "Accuracy: 91.89 %\n",
      "Epoch: 900\n",
      "Accuracy: 92.07 %\n",
      "Epoch: 950\n",
      "Accuracy: 92.25 %\n",
      "Epoch: 999\n",
      "Accuracy: 92.42 %\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2, W3, b3 = train(X_train, Y_train, 1000, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04d6f9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [0]\n",
      "actual: 0\n",
      "confidence: [0.99999222]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_results(np.random.randint(0, Y_train.size), W1, b1, W2, b2, W3, b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8afb9ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = make_predictions(X_test, W1, b1, W2, b2, W3, b3)\n",
    "get_accuracy(test_predictions, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "384cfc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Accuracy: 94.6 %\n",
      "Epoch: 50\n",
      "Accuracy: 94.6 %\n",
      "Epoch: 100\n",
      "Accuracy: 94.61 %\n",
      "Epoch: 150\n",
      "Accuracy: 94.62 %\n",
      "Epoch: 200\n",
      "Accuracy: 94.63 %\n",
      "Epoch: 250\n",
      "Accuracy: 94.64 %\n",
      "Epoch: 300\n",
      "Accuracy: 94.66 %\n",
      "Epoch: 350\n",
      "Accuracy: 94.66 %\n",
      "Epoch: 400\n",
      "Accuracy: 94.66 %\n",
      "Epoch: 450\n",
      "Accuracy: 94.67 %\n",
      "Epoch: 500\n",
      "Accuracy: 94.68 %\n",
      "Epoch: 550\n",
      "Accuracy: 94.68 %\n",
      "Epoch: 600\n",
      "Accuracy: 94.69 %\n",
      "Epoch: 650\n",
      "Accuracy: 94.7 %\n",
      "Epoch: 700\n",
      "Accuracy: 94.72 %\n",
      "Epoch: 750\n",
      "Accuracy: 94.72 %\n",
      "Epoch: 800\n",
      "Accuracy: 94.73 %\n",
      "Epoch: 850\n",
      "Accuracy: 94.74 %\n",
      "Epoch: 900\n",
      "Accuracy: 94.76 %\n",
      "Epoch: 950\n",
      "Accuracy: 94.76 %\n",
      "Epoch: 1000\n",
      "Accuracy: 94.77 %\n",
      "Epoch: 1050\n",
      "Accuracy: 94.77 %\n",
      "Epoch: 1100\n",
      "Accuracy: 94.78 %\n",
      "Epoch: 1150\n",
      "Accuracy: 94.78 %\n",
      "Epoch: 1200\n",
      "Accuracy: 94.79 %\n",
      "Epoch: 1250\n",
      "Accuracy: 94.79 %\n",
      "Epoch: 1300\n",
      "Accuracy: 94.79 %\n",
      "Epoch: 1350\n",
      "Accuracy: 94.8 %\n",
      "Epoch: 1400\n",
      "Accuracy: 94.81 %\n",
      "Epoch: 1450\n",
      "Accuracy: 94.81 %\n",
      "Epoch: 1500\n",
      "Accuracy: 94.81 %\n",
      "Epoch: 1550\n",
      "Accuracy: 94.82 %\n",
      "Epoch: 1600\n",
      "Accuracy: 94.83 %\n",
      "Epoch: 1650\n",
      "Accuracy: 94.83 %\n",
      "Epoch: 1700\n",
      "Accuracy: 94.84 %\n",
      "Epoch: 1750\n",
      "Accuracy: 94.84 %\n",
      "Epoch: 1800\n",
      "Accuracy: 94.85 %\n",
      "Epoch: 1850\n",
      "Accuracy: 94.86 %\n",
      "Epoch: 1900\n",
      "Accuracy: 94.86 %\n",
      "Epoch: 1950\n",
      "Accuracy: 94.86 %\n",
      "Epoch: 2000\n",
      "Accuracy: 94.87 %\n",
      "Epoch: 2050\n",
      "Accuracy: 94.87 %\n",
      "Epoch: 2100\n",
      "Accuracy: 94.87 %\n",
      "Epoch: 2150\n",
      "Accuracy: 94.88 %\n",
      "Epoch: 2200\n",
      "Accuracy: 94.88 %\n",
      "Epoch: 2250\n",
      "Accuracy: 94.88 %\n",
      "Epoch: 2300\n",
      "Accuracy: 94.89 %\n",
      "Epoch: 2350\n",
      "Accuracy: 94.9 %\n",
      "Epoch: 2400\n",
      "Accuracy: 94.89 %\n",
      "Epoch: 2450\n",
      "Accuracy: 94.89 %\n",
      "Epoch: 2500\n",
      "Accuracy: 94.9 %\n",
      "Epoch: 2550\n",
      "Accuracy: 94.9 %\n",
      "Epoch: 2600\n",
      "Accuracy: 94.91 %\n",
      "Epoch: 2650\n",
      "Accuracy: 94.92 %\n",
      "Epoch: 2700\n",
      "Accuracy: 94.92 %\n",
      "Epoch: 2750\n",
      "Accuracy: 94.93 %\n",
      "Epoch: 2800\n",
      "Accuracy: 94.93 %\n",
      "Epoch: 2850\n",
      "Accuracy: 94.94 %\n",
      "Epoch: 2900\n",
      "Accuracy: 94.95 %\n",
      "Epoch: 2950\n",
      "Accuracy: 94.95 %\n",
      "Epoch: 3000\n",
      "Accuracy: 94.96 %\n",
      "Epoch: 3050\n",
      "Accuracy: 94.97 %\n",
      "Epoch: 3100\n",
      "Accuracy: 94.98 %\n",
      "Epoch: 3150\n",
      "Accuracy: 94.99 %\n",
      "Epoch: 3200\n",
      "Accuracy: 95.0 %\n",
      "Epoch: 3250\n",
      "Accuracy: 95.0 %\n",
      "Epoch: 3300\n",
      "Accuracy: 95.0 %\n",
      "Epoch: 3350\n",
      "Accuracy: 95.0 %\n",
      "Epoch: 3400\n",
      "Accuracy: 95.0 %\n",
      "Epoch: 3450\n",
      "Accuracy: 95.0 %\n",
      "Epoch: 3500\n",
      "Accuracy: 95.01 %\n",
      "Epoch: 3550\n",
      "Accuracy: 95.01 %\n",
      "Epoch: 3600\n",
      "Accuracy: 95.03 %\n",
      "Epoch: 3650\n",
      "Accuracy: 95.03 %\n",
      "Epoch: 3700\n",
      "Accuracy: 95.03 %\n",
      "Epoch: 3750\n",
      "Accuracy: 95.03 %\n",
      "Epoch: 3800\n",
      "Accuracy: 95.03 %\n",
      "Epoch: 3850\n",
      "Accuracy: 95.03 %\n",
      "Epoch: 3900\n",
      "Accuracy: 95.04 %\n",
      "Epoch: 3950\n",
      "Accuracy: 95.04 %\n",
      "Epoch: 4000\n",
      "Accuracy: 95.04 %\n",
      "Epoch: 4050\n",
      "Accuracy: 95.05 %\n",
      "Epoch: 4100\n",
      "Accuracy: 95.06 %\n",
      "Epoch: 4150\n",
      "Accuracy: 95.07 %\n",
      "Epoch: 4200\n",
      "Accuracy: 95.08 %\n",
      "Epoch: 4250\n",
      "Accuracy: 95.08 %\n",
      "Epoch: 4300\n",
      "Accuracy: 95.08 %\n",
      "Epoch: 4350\n",
      "Accuracy: 95.09 %\n",
      "Epoch: 4400\n",
      "Accuracy: 95.1 %\n",
      "Epoch: 4450\n",
      "Accuracy: 95.1 %\n",
      "Epoch: 4500\n",
      "Accuracy: 95.1 %\n",
      "Epoch: 4550\n",
      "Accuracy: 95.1 %\n",
      "Epoch: 4600\n",
      "Accuracy: 95.11 %\n",
      "Epoch: 4650\n",
      "Accuracy: 95.12 %\n",
      "Epoch: 4700\n",
      "Accuracy: 95.13 %\n",
      "Epoch: 4750\n",
      "Accuracy: 95.13 %\n",
      "Epoch: 4800\n",
      "Accuracy: 95.14 %\n",
      "Epoch: 4850\n",
      "Accuracy: 95.15 %\n",
      "Epoch: 4900\n",
      "Accuracy: 95.15 %\n",
      "Epoch: 4950\n",
      "Accuracy: 95.15 %\n",
      "Epoch: 5000\n",
      "Accuracy: 95.15 %\n",
      "Epoch: 5050\n",
      "Accuracy: 95.16 %\n",
      "Epoch: 5100\n",
      "Accuracy: 95.16 %\n",
      "Epoch: 5150\n",
      "Accuracy: 95.17 %\n",
      "Epoch: 5200\n",
      "Accuracy: 95.18 %\n",
      "Epoch: 5250\n",
      "Accuracy: 95.19 %\n",
      "Epoch: 5300\n",
      "Accuracy: 95.19 %\n",
      "Epoch: 5350\n",
      "Accuracy: 95.19 %\n",
      "Epoch: 5400\n",
      "Accuracy: 95.19 %\n",
      "Epoch: 5450\n",
      "Accuracy: 95.2 %\n",
      "Epoch: 5500\n",
      "Accuracy: 95.2 %\n",
      "Epoch: 5550\n",
      "Accuracy: 95.2 %\n",
      "Epoch: 5600\n",
      "Accuracy: 95.21 %\n",
      "Epoch: 5650\n",
      "Accuracy: 95.22 %\n",
      "Epoch: 5700\n",
      "Accuracy: 95.22 %\n",
      "Epoch: 5750\n",
      "Accuracy: 95.23 %\n",
      "Epoch: 5800\n",
      "Accuracy: 95.23 %\n",
      "Epoch: 5850\n",
      "Accuracy: 95.23 %\n",
      "Epoch: 5900\n",
      "Accuracy: 95.24 %\n",
      "Epoch: 5950\n",
      "Accuracy: 95.24 %\n",
      "Epoch: 6000\n",
      "Accuracy: 95.26 %\n",
      "Epoch: 6050\n",
      "Accuracy: 95.25 %\n",
      "Epoch: 6100\n",
      "Accuracy: 95.26 %\n",
      "Epoch: 6150\n",
      "Accuracy: 95.27 %\n",
      "Epoch: 6200\n",
      "Accuracy: 95.28 %\n",
      "Epoch: 6250\n",
      "Accuracy: 95.28 %\n",
      "Epoch: 6300\n",
      "Accuracy: 95.29 %\n",
      "Epoch: 6350\n",
      "Accuracy: 95.29 %\n",
      "Epoch: 6400\n",
      "Accuracy: 95.3 %\n",
      "Epoch: 6450\n",
      "Accuracy: 95.3 %\n",
      "Epoch: 6500\n",
      "Accuracy: 95.31 %\n",
      "Epoch: 6550\n",
      "Accuracy: 95.31 %\n",
      "Epoch: 6600\n",
      "Accuracy: 95.31 %\n",
      "Epoch: 6650\n",
      "Accuracy: 95.31 %\n",
      "Epoch: 6700\n",
      "Accuracy: 95.32 %\n",
      "Epoch: 6750\n",
      "Accuracy: 95.33 %\n",
      "Epoch: 6800\n",
      "Accuracy: 95.33 %\n",
      "Epoch: 6850\n",
      "Accuracy: 95.33 %\n",
      "Epoch: 6900\n",
      "Accuracy: 95.34 %\n",
      "Epoch: 6950\n",
      "Accuracy: 95.34 %\n",
      "Epoch: 7000\n",
      "Accuracy: 95.35 %\n",
      "Epoch: 7050\n",
      "Accuracy: 95.36 %\n",
      "Epoch: 7100\n",
      "Accuracy: 95.36 %\n",
      "Epoch: 7150\n",
      "Accuracy: 95.37 %\n",
      "Epoch: 7200\n",
      "Accuracy: 95.38 %\n",
      "Epoch: 7250\n",
      "Accuracy: 95.38 %\n",
      "Epoch: 7300\n",
      "Accuracy: 95.4 %\n",
      "Epoch: 7350\n",
      "Accuracy: 95.4 %\n",
      "Epoch: 7400\n",
      "Accuracy: 95.4 %\n",
      "Epoch: 7450\n",
      "Accuracy: 95.4 %\n",
      "Epoch: 7500\n",
      "Accuracy: 95.4 %\n",
      "Epoch: 7550\n",
      "Accuracy: 95.4 %\n",
      "Epoch: 7600\n",
      "Accuracy: 95.41 %\n",
      "Epoch: 7650\n",
      "Accuracy: 95.41 %\n",
      "Epoch: 7700\n",
      "Accuracy: 95.42 %\n",
      "Epoch: 7750\n",
      "Accuracy: 95.43 %\n",
      "Epoch: 7800\n",
      "Accuracy: 95.44 %\n",
      "Epoch: 7850\n",
      "Accuracy: 95.45 %\n",
      "Epoch: 7900\n",
      "Accuracy: 95.46 %\n",
      "Epoch: 7950\n",
      "Accuracy: 95.46 %\n",
      "Epoch: 8000\n",
      "Accuracy: 95.47 %\n",
      "Epoch: 8050\n",
      "Accuracy: 95.48 %\n",
      "Epoch: 8100\n",
      "Accuracy: 95.49 %\n",
      "Epoch: 8150\n",
      "Accuracy: 95.49 %\n",
      "Epoch: 8200\n",
      "Accuracy: 95.5 %\n",
      "Epoch: 8250\n",
      "Accuracy: 95.49 %\n",
      "Epoch: 8300\n",
      "Accuracy: 95.5 %\n",
      "Epoch: 8350\n",
      "Accuracy: 95.5 %\n",
      "Epoch: 8400\n",
      "Accuracy: 95.51 %\n",
      "Epoch: 8450\n",
      "Accuracy: 95.52 %\n",
      "Epoch: 8500\n",
      "Accuracy: 95.52 %\n",
      "Epoch: 8550\n",
      "Accuracy: 95.53 %\n",
      "Epoch: 8600\n",
      "Accuracy: 95.53 %\n",
      "Epoch: 8650\n",
      "Accuracy: 95.54 %\n",
      "Epoch: 8700\n",
      "Accuracy: 95.54 %\n",
      "Epoch: 8750\n",
      "Accuracy: 95.54 %\n",
      "Epoch: 8800\n",
      "Accuracy: 95.55 %\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2, W3, b3 = continue_train(X_train, Y_train, 10000, 0.01, W1, b1, W2, b2, W3, b3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
