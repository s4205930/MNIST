{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('MNIST.csv')\n",
    "data = np.array(data)\n",
    "np.random.shuffle(data)\n",
    "\n",
    "m, n = data.shape\n",
    "\n",
    "data_test = data[0:1000].T\n",
    "Y_test = data_test[0]\n",
    "X_test = data_test[1:n]\n",
    "X_test = X_test / 255\n",
    "\n",
    "data_train = data[1000:m].T\n",
    "Y_train = data_train[0]\n",
    "X_train = data_train[1:n]\n",
    "X_train = X_train / 255\n",
    "\n",
    "_, m_train = X_train.shape\n",
    "\n",
    "def ReLU(Z):\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "def softmax(Z):\n",
    "    A = np.exp(Z) / sum(np.exp(Z))\n",
    "    return A\n",
    "\n",
    "class Neural_Network:\n",
    "    def __init__(self, input_size, hidden_1_size, output_size, bias = 1):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_1_size = hidden_1_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.fitness = 0\n",
    "\n",
    "        self.W1 = np.random.rand(hidden_1_size, input_size) - 0.5\n",
    "        self.b1 = np.random.rand(hidden_1_size, bias) - 0.5\n",
    "\n",
    "        self.W2 = np.random.rand(output_size, hidden_1_size) - 0.5\n",
    "        self.b2 = np.random.rand(output_size, bias) - 0.5\n",
    "\n",
    "    def copy(self):\n",
    "        new_nn = Neural_Network(0, 0, 0)\n",
    "        new_nn.W1 = self.W1.copy()\n",
    "        new_nn.b1 = self.b1.copy()\n",
    "        new_nn.W2 = self.W2.copy()\n",
    "        new_nn.b2 = self.b2.copy()\n",
    "        return new_nn\n",
    "\n",
    "    def forward_prop(self, X):\n",
    "        self.Z1 = self.W1.dot(X) + self.b1\n",
    "        self.A1 = ReLU(self.Z1)\n",
    "\n",
    "        self.Z2 = self.W2.dot(self.A1)\n",
    "        self.A2 = softmax(self.Z2)\n",
    "\n",
    "        return self.A2\n",
    "\n",
    "\n",
    "def fitness_function(network, X_train, Y_train):\n",
    "    network.forward_prop(X_train)\n",
    "    predictions = np.argmax(network.A2, axis=0)\n",
    "    network.fitness = np.sum(predictions == Y_train) / Y_train.size\n",
    "    return network.fitness\n",
    "\n",
    "def init_pop(pop_size):\n",
    "    population = []\n",
    "    for _ in range(pop_size):\n",
    "        network = Neural_Network(784, 10, 10)\n",
    "        population.append(network)\n",
    "    return population\n",
    "\n",
    "def select_parents(population, X, y):\n",
    "    fitness_scores = [fitness_function(network, X, y) for network in population]\n",
    "    total_fitness = sum(fitness_scores)\n",
    "    probabilities = [score / total_fitness for score in fitness_scores]\n",
    "    selected_indices = np.random.choice(len(population), size = 2, p = probabilities, replace = False)\n",
    "    parent_1 = population[selected_indices[0]].copy()\n",
    "    parent_2 = population[selected_indices[1]].copy()\n",
    "    return parent_1, parent_2\n",
    "\n",
    "def crossover(parent_1, parent_2):\n",
    "    child = Neural_Network(0, 0, 0)  # Initialise with dummy values\n",
    "\n",
    "    # Crossover W1\n",
    "    mask = np.random.rand(*parent_1.W1.shape) < 0.5\n",
    "    child.W1 = np.where(mask, parent_1.W1, parent_2.W1)\n",
    "\n",
    "    # Crossover b1\n",
    "    mask = np.random.rand(*parent_1.b1.shape) < 0.5\n",
    "    child.b1 = np.where(mask, parent_1.b1, parent_2.b1)\n",
    "\n",
    "    # Crossover W2\n",
    "    mask = np.random.rand(*parent_1.W2.shape) < 0.5\n",
    "    child.W2 = np.where(mask, parent_1.W2, parent_2.W2)\n",
    "\n",
    "    # Crossover b2\n",
    "    mask = np.random.rand(*parent_1.b2.shape) < 0.5\n",
    "    child.b2 = np.where(mask, parent_1.b2, parent_2.b2)\n",
    "\n",
    "    return child\n",
    "\n",
    "def mutate(network, mutation_rate):\n",
    "    # Mutate W1\n",
    "    mutation_mask = np.random.rand(*network.W1.shape) < mutation_rate\n",
    "    network.W1 += mutation_mask * np.random.randn(*network.W1.shape) * 0.1\n",
    "\n",
    "    # Mutate b1\n",
    "    mutation_mask = np.random.rand(*network.b1.shape) < mutation_rate\n",
    "    network.b1 += mutation_mask * np.random.randn(*network.b1.shape) * 0.1\n",
    "\n",
    "    # Mutate W2\n",
    "    mutation_mask = np.random.rand(*network.W2.shape) < mutation_rate\n",
    "    network.W2 += mutation_mask * np.random.randn(*network.W2.shape) * 0.1\n",
    "\n",
    "    # Mutate b2\n",
    "    mutation_mask = np.random.rand(*network.b2.shape) < mutation_rate\n",
    "    network.b2 += mutation_mask * np.random.randn(*network.b2.shape) * 0.1\n",
    "\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  :  15.0561 %\n",
      "1  :  13.2024 %\n",
      "2  :  18.6683 %\n",
      "3  :  21.0073 %\n",
      "4  :  17.1488 %\n",
      "5  :  16.222 %\n",
      "6  :  14.478 %\n",
      "7  :  14.439 %\n",
      "8  :  13.9073 %\n",
      "9  :  11.939 %\n",
      "10  :  13.6854 %\n",
      "11  :  12.3488 %\n",
      "12  :  13.2049 %\n",
      "13  :  13.2732 %\n",
      "14  :  12.3488 %\n",
      "15  :  13.5146 %\n",
      "16  :  14.3488 %\n",
      "17  :  12.9171 %\n",
      "18  :  13.7854 %\n",
      "19  :  14.5341 %\n",
      "20  :  13.7195 %\n",
      "21  :  12.6561 %\n",
      "22  :  14.5902 %\n",
      "23  :  11.8293 %\n",
      "24  :  13.3073 %\n",
      "25  :  12.8927 %\n",
      "26  :  14.3878 %\n",
      "27  :  13.2415 %\n",
      "28  :  15.0171 %\n",
      "29  :  14.3756 %\n",
      "30  :  13.8561 %\n",
      "31  :  14.8366 %\n",
      "32  :  13.7488 %\n",
      "33  :  14.1439 %\n",
      "34  :  15.8415 %\n",
      "35  :  15.9561 %\n",
      "36  :  14.1707 %\n",
      "37  :  13.9683 %\n",
      "38  :  13.6902 %\n"
     ]
    }
   ],
   "source": [
    "pop_size = 20\n",
    "mutation_rate = 0.05\n",
    "generations = 150\n",
    "\n",
    "\n",
    "population = init_pop(pop_size)\n",
    "best_ever_network = max(population, key=lambda x: fitness_function(x, X_train, Y_train))\n",
    "\n",
    "# for generation in range(generations):\n",
    "generation = -1\n",
    "while (best_ever_network.fitness < 0.9):\n",
    "    generation += 1\n",
    "\n",
    "    best_network = max(population, key=lambda x: fitness_function(x, X_train, Y_train))\n",
    "\n",
    "    if (fitness_function(best_network, X_train, Y_train) > fitness_function(best_ever_network, X_train, Y_train)):\n",
    "        best_ever_network = best_network\n",
    "\n",
    "    print(generation, ' : ', round(fitness_function(best_network, X_train, Y_train) * 100, 4), '%')\n",
    "\n",
    "    new_population = []\n",
    "\n",
    "    for _ in range(pop_size // 2):\n",
    "        parent_1, parent_2 = select_parents(population, X_train, Y_train)\n",
    "\n",
    "        child_1 = crossover(parent_1, parent_2)\n",
    "        child_1 = mutate(child_1, mutation_rate)\n",
    "\n",
    "        child_2 = crossover(parent_1, parent_2)\n",
    "        child_2 = mutate(child_2, mutation_rate)\n",
    "\n",
    "        new_population.extend([child_1, child_2])\n",
    "    population = new_population \n",
    "\n",
    "\n",
    "if (fitness_function(best_network, X_train, Y_train) > fitness_function(best_ever_network, X_train, Y_train)):\n",
    "        best_ever_network = best_network\n",
    "\n",
    "print('Test accuracy:', round(fitness_function(best_ever_network, X_test, Y_test) * 100, 4), '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
